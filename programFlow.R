library("ShortRead")
library("BSgenome")

bsub <- function(cpus=1, maxmem=NULL, wait=NULL, jobName=NULL, logFile=NULL, command=NULL){
  stopifnot(!is.null(maxmem))
  if(Sys.Date()>=as.Date("2015-06-01", "%Y-%m-%d")){
    queue <- "normal"
  }else{
    queue <- "umem"
  }

  cmd <- paste0("bsub -q ", queue, " -n ", as.character(cpus), " -M ", maxmem)
  
  if(!is.null(wait)){
    cmd <- paste0(cmd, " -w \"", wait, "\"")
  }
  
  if(!is.null(jobName)){
    cmd <- paste0(cmd, " -J \"", jobName, "\"")
  }
  
  if(!is.null(logFile)){
    cmd <- paste0(cmd, " -o ", logFile)
  }
  
  cmd <- paste0(cmd, " ", command) #no default, should crash if no command provided
  cat(cmd, "\n")
  system(cmd)
}

#takes a textual genome identifier (ie. hg18) and turns it into the correct
#BSgenome object
get_reference_genome <- function(reference_genome) {
  pattern <- paste0("\\.", reference_genome, "$")
  match_index <- which(grepl(pattern, installed.genomes()))
  if (length(match_index) != 1) {
    write("Installed genomes are:", stderr())
    write(installed.genomes(), stderr())
    stop(paste("Cannot find unique genome for", reference_genome))
  }
  BS_genome_full_name <- installed.genomes()[match_index]
  library(BS_genome_full_name, character.only=T)
  get(BS_genome_full_name)
}

alignSeqs <- function(){
  # do alignments  
  toAlign <- system("ls */*.fa", intern=T)
  alignFile <- toAlign[as.integer(system("echo $LSB_JOBINDEX", intern=T))]
  alias <- strsplit(alignFile, "/")[[1]][1]
  
  completeMetadata <- get(load("completeMetadata.RData"))
  genome <- completeMetadata[completeMetadata$alias==alias,"refGenome"]
  indexPath <- paste0(genome, ".2bit")
  
  system(paste0("blat ", indexPath, " ", alignFile, " -ooc=", genome, ".11.ooc ", alignFile, ".psl -tileSize=11 -repMatch=112312 -t=dna -q=dna -minIdentity=85 -minScore=27 -dots=1000 -out=psl -noHead"))
  system(paste0("gzip ", alignFile, ".psl"))
}

callIntSites <- function(){
  codeDir <- get(load("codeDir.RData"))
  source(paste0(codeDir, "/intSiteLogic.R"))
  
  sampleID <- as.integer(system("echo $LSB_JOBINDEX", intern=T))
  
  completeMetadata <- get(load("completeMetadata.RData"))[sampleID,]

  status <- tryCatch(eval(as.call(append(processAlignments,
                                         unname(as.list(completeMetadata[c("alias", "minPctIdent",
                                                                           "maxAlignStart", "maxFragLength",
                                                                           "refGenome")]))))),
                     error=function(e){print(paste0("Caught error: ", e$message))})

  save(status, file="callStatus.RData") #working directory is changed while executing getTrimmedSeqs
}

demultiplex <- function(){
  I1 <- readFasta(list.files("Data", pattern="correctedI1-.", full.names=T))
  
  completeMetadata <- get(load("completeMetadata.RData"))
  
  I1 <- I1[as.vector(sread(I1)) %in% completeMetadata$bcSeq]
  samples <- completeMetadata[match(as.character(sread(I1)), completeMetadata$bcSeq), "alias"]
  
  #only necessary if using native data - can parse out description w/ python
  I1Names <-  sapply(strsplit(as.character(ShortRead::id(I1)), " "), "[[", 1)#for some reason we can't dynamically set name/id on ShortRead!
  
  suppressWarnings(dir.create("Data/demultiplexedReps"))
  
  R1 <- readFastq("Data/Undetermined_S0_L001_R1_001.fastq.gz")
  demultiplex_reads(R1, "R1", I1Names, samples, completeMetadata)
  
  R2 <- readFastq("Data/Undetermined_S0_L001_R2_001.fastq.gz")
  demultiplex_reads(R2, "R2", I1Names, samples, completeMetadata)
}

#' write fastq for each barcode and each sample
#' @param reads fastq reads as parsed by readFastq()
#' @param suffix either "R1" or "R2"
demultiplex_reads <- function(reads, suffix, I1Names, samples, completeMetadata) {
    RNames <- sapply(strsplit(as.character(ShortRead::id(reads)), " "), "[[", 1)#for some reason we can't dynamically set name/id on ShortRead!
    names(RNames) <- NULL

    reads <- reads[match(I1Names, RNames)]
    reads <- split(reads, samples)
    for (i in 1:length(reads)){
        barcode.i <- completeMetadata$bcSeq[ completeMetadata$alias == names(reads)[i] ]
        stopifnot(length(barcode.i)==1)
        alias_by_barcode <- completeMetadata$alias[ completeMetadata$bcSeq == barcode.i ]
        stopifnot(length(alias_by_barcode)>=1)
        fqFiles <- paste0("Data/demultiplexedReps/", alias_by_barcode, "_", suffix, ".fastq.gz")
        cat(barcode.i, "\t", paste(fqFiles, collapse=" "), "\n" )
        null <- sapply(fqFiles, function(fq) writeFastq(reads[[i]], fq, mode="w") )
    }  
}

errorCorrectBC <- function(){
  library("ShortRead")
  
  codeDir <- get(load("codeDir.RData"))
  completeMetadata <- get(load("completeMetadata.RData"))
  bushmanJobID <- get(load("bushmanJobID.RData"))
  
  I1 <- readFastq("Data/Undetermined_S0_L001_I1_001.fastq.gz")
  I1 <- trimTailw(I1, 2, "0", 12)
  I1 <- I1[width(I1)==max(width(I1))]
  
  I1 <- split(I1, ceiling(seq_along(I1)/500000))
  
  for(chunk in names(I1)){
    writeFasta(I1[[chunk]], file=paste0("Data/trimmedI1-", chunk, ".fasta"))
  }
    
  bsub(jobName=paste0("BushmanErrorCorrectWorker_", bushmanJobID, "[1-", length(I1),"]"),
       maxmem=1000,
       logFile="logs/errorCorrectWorkerOutput%I.txt",
       command=paste0("python ", codeDir, "/errorCorrectIndices/processGolay.py")
  )
  
  bsub(wait=paste0("done(BushmanErrorCorrectWorker_", bushmanJobID, ")"),
       jobName=paste0("BushmanDemultiplex_", bushmanJobID),
       maxmem=64000, #just in case
       logFile="logs/demultiplexOutput.txt",
       command=paste0("Rscript -e \"source('", codeDir, "/programFlow.R'); demultiplex();\"")
  )
  
  #trim seqs
  bsub(wait=paste0("done(BushmanDemultiplex_", bushmanJobID, ")"),
       jobName=paste0("BushmanTrimReads_", bushmanJobID, "[1-", nrow(completeMetadata), "]"),
       maxmem=16000,
       logFile="logs/trimOutput%I.txt",
       command=paste0("Rscript -e \"source('", codeDir, "/programFlow.R'); trimReads();\"")
  )
  
  #post-trim processing, also kicks off alignment and int site calling jobs
  bsub(wait=paste0("done(BushmanTrimReads_", bushmanJobID, ")"),
       jobName=paste0("BushmanPostTrimProcessing_", bushmanJobID),
       maxmem=8000,
       logFile="logs/postTrimOutput.txt",
       command=paste0("Rscript -e \"source('", codeDir, "/programFlow.R'); postTrimReads();\"")
  )
}

postTrimReads <- function(){
# the first place where reference genome is used
  library("BSgenome")
  library("rtracklayer") #needed for exporting genome to 2bit
  completeMetadata <- get(load("completeMetadata.RData"))
  codeDir <- get(load("codeDir.RData"))
  bushmanJobID <- get(load("bushmanJobID.RData"))
  
  numAliases <- nrow(completeMetadata)
  
  numFastaFiles <- length(system("ls */*.fa", intern=T))
  
  #make temp genomes
  genomesToMake <- unique(completeMetadata$refGenome)
  
  for(genome in genomesToMake){
    export(get_reference_genome(genome), paste0(genome, ".2bit"))
    system(paste0("blat ", genome, ".2bit /dev/null /dev/null -makeOoc=", genome, ".11.ooc"))
  }
    
  #align seqs
  bsub(wait=paste0("done(BushmanPostTrimProcessing_", bushmanJobID, ")"),
       jobName=paste0("BushmanAlignSeqs_", bushmanJobID, "[1", "-", numFastaFiles, "]"),
       maxmem=8000,
       logFile="logs/alignOutput%I.txt",
       command=paste0("Rscript -e \"source('", codeDir, "/programFlow.R'); alignSeqs();\"")
  )

  #call int sites (have to find out which ones worked)
  successfulTrims <- unname(sapply(completeMetadata$alias, function(x){
    get(load(paste0(x, "/trimStatus.RData"))) == x    
  }))
  
  jobArrayID <- which(successfulTrims)
  for(ID in jobArrayID) {
      bsub(wait=paste0("done(BushmanAlignSeqs_", bushmanJobID, ")"),
           jobName=paste0("BushmanCallIntSites_", bushmanJobID, "[", ID, "]"),
           maxmem=24000, #multihits suck lots of memory
           logFile="logs/callSitesOutput%I.txt",
           command=paste0("Rscript -e \"source('", codeDir, "/programFlow.R'); callIntSites();\"")
           )
  }
  
}

trimReads <- function(){
  codeDir <- get(load("codeDir.RData"))
  source(paste0(codeDir, "/intSiteLogic.R"))
  
  sampleID <- as.integer(system("echo $LSB_JOBINDEX", intern=T))
  
  completeMetadata <- get(load("completeMetadata.RData"))[sampleID,]
    
  alias <- completeMetadata$alias
  
  suppressWarnings(dir.create(alias, recursive=TRUE))
  
  status <- tryCatch(eval(as.call(append(getTrimmedSeqs,
                                         unname(as.list(completeMetadata[c("qualityThreshold", "badQualityBases",
                                                                           "qualitySlidingWindow", "primer", "ltrBit",
                                                                           "largeLTRFrag", "linkerSequence", "linkerCommon",
                                                                           "mingDNA", "read1", "read2", "alias", "vectorSeq")]))))),
                     error=function(e){print(paste0("Caught error: ", e$message))})
  
  save(status, file="trimStatus.RData") #working directory is changed while executing getTrimmedSeqs
}

processMetadata <- function(){

  bushmanJobID <- parsedArgs$jobID
  
  #stop if any jobs already exist with the same job ID as this will confuse LSF
  stopifnot(!any(grepl(bushmanJobID, suppressWarnings(system("bjobs -l | grep -o \"Job Name <[^>]*>\"", intern=T)))))
  
  #expand codeDir to absolute path for saving
  codeDir <- normalizePath(parsedArgs$codeDir)

    source(file.path(codeDir, 'linker_common.R'))
    source(file.path(codeDir, 'read_sample_files.R'))

  #setting R's working dir also sets shell location for system calls, thus
  #primaryAnalysisDir is propagated without being saved
  setwd(parsedArgs$primaryAnalysisDir)

  save(bushmanJobID, file=paste0(getwd(), "/bushmanJobID.RData"))
  save(codeDir, file=paste0(getwd(), "/codeDir.RData"))

    sample_file <- 'sampleInfo.tsv'
    proc_file <- "processingParams.tsv"
    if ( ! file.exists(proc_file)) { # have to use default
        default <- "default_processingParams.tsv"
        proc_file <- file.path(codeDir, default)
    }
    completeMetadata <- read_sample_processing_files(sample_file, proc_file)
  
  completeMetadata$read1 <- paste0(getwd(), "/Data/demultiplexedReps/", completeMetadata$alias, "_R1.fastq.gz")
  completeMetadata$read2 <- paste0(getwd(), "/Data/demultiplexedReps/", completeMetadata$alias, "_R2.fastq.gz")

  stopifnot(all(c("qualityThreshold", "badQualityBases", "qualitySlidingWindow",
                  "primer", "ltrBit", "largeLTRFrag", "linkerSequence", "linkerCommon",
                  "mingDNA", "read1", "read2", "alias", "vectorSeq", "minPctIdent",
                  "maxAlignStart", "maxFragLength", "gender") %in% names(completeMetadata)))
  
  stopifnot(all( file.exists(completeMetadata$vectorSeq) ))
  
  save(completeMetadata, file="completeMetadata.RData")

  suppressWarnings(dir.create("logs"))

  #error-correct barcodes - kicks off subsequent steps
  bsub(jobName=paste0("BushmanErrorCorrect_", bushmanJobID),
       maxmem=20000,
       logFile="logs/errorCorrectOutput.txt",
       command=paste0("Rscript -e \"source('", codeDir, "/programFlow.R'); errorCorrectBC();\"")
  )
}
